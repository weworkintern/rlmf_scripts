{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_ndjson(\"data/gym/dump_prompt_solution_gym_0605_e.jsonl\")\n",
    "\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.filter(pl.col(\"title\").str.contains(r\"[^\\x00-\\x7F]\") & \n",
    "                ~pl.col(\"title\").str.contains(r\"^[A-Za-z0-9\\s\\p{P}]*$\"))\n",
    "\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df2[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df2 = df2.filter(pl.col(\"prompt\").str.contains(r\"[^\\x00-\\x7F]\") & \n",
    "                ~pl.col(\"prompt\").str.contains(r\"^[A-Za-z0-9\\s\\p{P}]*$\"))\n",
    "\n",
    "diff_df2 = df2.filter(~(pl.col(\"prompt\").str.contains(r\"[^\\x00-\\x7F]\") & \n",
    "                ~pl.col(\"prompt\").str.contains(r\"^[A-Za-z0-9\\s\\p{P}]*$\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(diff_df2[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.filter(pl.col(\"prompt\").str.contains(r\"[^\\x00-\\x7F]\") & \n",
    "                ~pl.col(\"prompt\").str.contains(r\"^[A-Za-z0-9\\s\\p{P}]*$\"))\n",
    "\n",
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "dfn = df.with_columns(pl.col(\"prompt\").map_elements(lambda s: detect(s) if s else \"EMPTY\").alias(\"lang\"))\n",
    "\n",
    "dfn[\"lang\", \"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_en = dfn.filter(pl.col(\"lang\") != \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START FROM HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and load data\n",
    "import polars as pl\n",
    "import re\n",
    "from langdetect import detect\n",
    "\n",
    "# Load the dataframes\n",
    "dfb = pl.read_ndjson(\"data/gym/dump_prompt_solution_gym_0605_b.jsonl\")\n",
    "dfc = pl.read_ndjson(\"data/gym/dump_prompt_solution_gym_0605_c.jsonl\")\n",
    "dfd = pl.read_ndjson(\"data/gym/dump_prompt_solution_gym_0605_d.jsonl\")\n",
    "dfe = pl.read_ndjson(\"data/gym/dump_prompt_solution_gym_0605_e.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(s: str):\n",
    "    return re.sub(r'<[/]?\\w+>', '', s)\n",
    "\n",
    "def detect_lang(s: str):\n",
    "    a = remove_tags(s)\n",
    "    try:\n",
    "        if a == \"\":\n",
    "            return \"EMPTY\"\n",
    "        return detect(a)\n",
    "    except Exception as e:\n",
    "        print(a, e)\n",
    "    return \"idk\"\n",
    "\n",
    "# Function to add language detection and split dataframe\n",
    "def split_by_lang(df):\n",
    "    # Add language detection\n",
    "    df_with_lang = df.with_columns(\n",
    "        pl.col(\"prompt\").map_elements(\n",
    "            lambda s: detect_lang(s) if s else \"EMPTY\", \n",
    "            return_dtype=pl.Utf8\n",
    "        ).alias(\"lang\"),\n",
    "        pl.col(\"title\").map_elements(\n",
    "            lambda s: detect_lang(s) if s else \"EMPTY\",\n",
    "            return_dtype=pl.Utf8\n",
    "        ).alias(\"lang_title\"),\n",
    "    )\n",
    "    \n",
    "    # Split into English/Empty and non-English/non-Empty\n",
    "    df_en = df_with_lang.filter((pl.col(\"lang\") == \"en\") | (pl.col(\"lang\") == \"EMPTY\") | (pl.col(\"lang_title\") == \"en\"))\n",
    "    df_non_en = df_with_lang.filter((pl.col(\"lang\") != \"en\") & (pl.col(\"lang\") != \"EMPTY\") & (pl.col(\"lang_title\") != \"en\"))\n",
    "    \n",
    "    return df_en, df_non_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810975 No features in text.\n",
      "+ - No features in text.\n",
      "42 No features in text.\n",
      "2300 No features in text.\n",
      "2024 No features in text.\n",
      "0:0 No features in text.\n",
      "= 10 No features in text.\n",
      "7485 No features in text.\n",
      "0689 No features in text.\n",
      "01 No features in text.\n",
      "2016 No features in text.\n",
      "\n",
      "dfb statistics:\n",
      "Total rows: 3000\n",
      "English/Empty: 2687 (89.6%)\n",
      "Non-English: 313 (10.4%)\n",
      "Sample of non-English languages: ['id', 'da', 'fr', 'it', 'tl', 'vi', 'ko', 'ru', 'ca', 'et', 'no', 'ro', 'af', 'es', 'tr', 'zh-cn', 'pt', 'sk']\n",
      "\n",
      "dfc statistics:\n",
      "Total rows: 3000\n",
      "English/Empty: 2670 (89.0%)\n",
      "Non-English: 330 (11.0%)\n",
      "Sample of non-English languages: ['no', 'cy', 'bn', 'uk', 'zh-cn', 'tr', 'vi', 'ca', 'fr', 'et', 'id', 'ru', 'da', 'es', 'pt', 'de', 'bg', 'af']\n",
      "\n",
      "dfd statistics:\n",
      "Total rows: 3000\n",
      "English/Empty: 2743 (91.4%)\n",
      "Non-English: 257 (8.6%)\n",
      "Sample of non-English languages: ['ru', 'ca', 'da', 'sk', 'bn', 'pt', 'es', 'cy', 'vi', 'no', 'hr', 'et', 'id', 'zh-cn', 'fr']\n",
      "\n",
      "dfe statistics:\n",
      "Total rows: 580\n",
      "English/Empty: 519 (89.5%)\n",
      "Non-English: 61 (10.5%)\n",
      "Sample of non-English languages: ['da', 'fr', 'et', 'ro', 'id', 'vi', 'ru', 'es', 'ca', 'hu', 'hr']\n"
     ]
    }
   ],
   "source": [
    "# Process each dataframe\n",
    "dfb_en, dfb_non_en = split_by_lang(dfb)\n",
    "dfc_en, dfc_non_en = split_by_lang(dfc)\n",
    "dfd_en, dfd_non_en = split_by_lang(dfd)\n",
    "dfe_en, dfe_non_en = split_by_lang(dfe)\n",
    "\n",
    "# Print statistics for each split\n",
    "for name, df_en, df_non_en in [\n",
    "    (\"dfb\", dfb_en, dfb_non_en),\n",
    "    (\"dfc\", dfc_en, dfc_non_en),\n",
    "    (\"dfd\", dfd_en, dfd_non_en),\n",
    "    (\"dfe\", dfe_en, dfe_non_en)\n",
    "]:\n",
    "    total = len(df_en) + len(df_non_en)\n",
    "    print(f\"\\n{name} statistics:\")\n",
    "    print(f\"Total rows: {total}\")\n",
    "    print(f\"English/Empty: {len(df_en)} ({len(df_en)/total*100:.1f}%)\")\n",
    "    print(f\"Non-English: {len(df_non_en)} ({len(df_non_en)/total*100:.1f}%)\")\n",
    "    \n",
    "    if len(df_non_en) > 0:\n",
    "        print(\"Sample of non-English languages:\", df_non_en.select(\"lang\").unique().to_series().to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to TRANSFER rows in non_en data frames that contain `iframe src=` in the `prompt` column to the en data frames\n",
    "\n",
    "dfb_non_en_ifr = dfb_non_en.filter(pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "dfc_non_en_ifr = dfc_non_en.filter(pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "dfd_non_en_ifr = dfd_non_en.filter(pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "dfe_non_en_ifr = dfe_non_en.filter(pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "\n",
    "# Combine these non_en_ifr rows back into the en data frames\n",
    "\n",
    "dfb_en = dfb_en.vstack(dfb_non_en_ifr)\n",
    "dfc_en = dfc_en.vstack(dfc_non_en_ifr)\n",
    "dfd_en = dfd_en.vstack(dfd_non_en_ifr)\n",
    "dfe_en = dfe_en.vstack(dfe_non_en_ifr)\n",
    "\n",
    "# And remove these rows from the non_en data frames\n",
    "\n",
    "dfb_non_en = dfb_non_en.filter(~pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "dfc_non_en = dfc_non_en.filter(~pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "dfd_non_en = dfd_non_en.filter(~pl.col(\"prompt\").str.contains(\"iframe src=\"))\n",
    "dfe_non_en = dfe_non_en.filter(~pl.col(\"prompt\").str.contains(\"iframe src=\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_b_en.jsonl\")\n",
    "dfc_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_c_en.jsonl\")\n",
    "dfd_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_d_en.jsonl\")\n",
    "dfe_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_e_en.jsonl\")\n",
    "\n",
    "dfb_non_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_b_non_en.jsonl\")\n",
    "dfc_non_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_c_non_en.jsonl\")\n",
    "dfd_non_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_d_non_en.jsonl\")\n",
    "dfe_non_en.write_ndjson(\"data/op/dump_prompt_solution_gym_0605_e_non_en.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = dfb_en.filter(pl.col(\"prompt_id\").str.contains(\"Gym/370346F\"))\n",
    "detect(str(dftest[\"prompt\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
